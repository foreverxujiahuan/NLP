# Logistic Regression

逻辑回归是机器学习中的一个经典模型，一般会用这样一个模型作为机器学习的入门模型

## 1.线性模型

首先考虑这样一个线性模型

$$ f(x) = w_1x_1 + w_2x_2 + w_3x_3 + ... + w_dx_4 + b$$

写成向量形式为

$$ f(x) = w^Tx + b$$

它能很好的表示根据一个$d$维的数据的各个特征值去预测它的$y$。

例如某个公司的员工工资和工龄、绩效和餐补$b$有关，那么该员工的工资可能就是工龄乘上某个系数$w_1$再加上绩效乘上某个系数$w_2$再加上餐补$b$

## 2.逻辑回归

但是线性模型只能做一些回归任务，那么如何做分类任务呢？

只要在线性模型外面加上一个激活函数即可,以sigomid为例

$$ f(x)  = sigmoid(w^Tx + b) $$

sigmoid可以将任意一个数字映射到0-1的范围内

$$ sigmoid(x) = \frac{1}{1 + e^-x}$$

因此它的输出可以作为一个概率分布，从而我们的模型可以用于分类任务。

## 3.逻辑回归的训练与预测

在机器学习中，我们常说的训练，就是就是去求解$w^$的过程,这里涉及到模型的反向传播与正向传播；预测则是在这些确定好的参数$w_T$上，进行数据推理的过程，这里只涉及到正向传播。